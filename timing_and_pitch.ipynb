{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'soundfile'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f724a2f4d3e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'soundfile'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local_path='/Users/Zizy/Programming/HKU/Dissertation/'\n",
    "reg = \"(.*) (.*) (.*)\\@(.*)\\^(.*)\\-(.*)\\+(.*)\\=(.*)\\_(.*)\\%(.*)\\^(.*)\\_(.*)\\~(.*)\\-(.*)\\!(.*)\\[(.*)\\$(.*)\\](.*)/A:(.*)\\-(.*)\\-(.*)\\@(.*)\\~(.*)/B:(.*)\\_(.*)\\_(.*)\\@(.*)\\|(.*)/C:(.*)\\+(.*)\\+(.*)\\@(.*)\\&(.*)/D:(.*)\\!(.*)\\#(.*)\\$(.*)\\%(.*)\\|(.*)\\&(.*)\\;(.*)\\-(.*)/E:(.*)\\](.*)\\^(.*)\\=(.*)\\~(.*)\\!(.*)\\@(.*)\\#(.*)\\+(.*)\\](.*)\\$(.*)\\|(.*)\\[(.*)\\&(.*)\\](.*)\\=(.*)\\^(.*)\\~(.*)\\#(.*)\\_(.*)\\;(.*)\\$(.*)\\&(.*)\\%(.*)\\[(.*)\\|(.*)\\](.*)\\-(.*)\\^(.*)\\+(.*)\\~(.*)\\=(.*)\\@(.*)\\$(.*)\\!(.*)\\%(.*)\\#(.*)\\|(.*)\\|(.*)\\-(.*)\\&(.*)\\&(.*)\\+(.*)\\[(.*)\\;(.*)\\](.*)\\;(.*)\\~(.*)\\~(.*)\\^(.*)\\^(.*)\\@(.*)\\[(.*)\\#(.*)\\=(.*)\\!(.*)\\~(.*)\\+(.*)\\!(.*)\\^(.*)/F:(.*)\\#(.*)\\#(.*)\\-(.*)\\$(.*)\\$(.*)\\+(.*)\\%(.*)\\;(.*)/G:(.*)\\_(.*)/H:(.*)\\_(.*)/I:(.*)\\_(.*)/J:(.*)\\~(.*)\\@(.*)\"\n",
    "li = re.findall(reg,\"0 12000000 p@xx^xx-pau+d=e_xx%xx^00_00~00-1!1[xx$xx]xx/A:xx-xx-xx@xx~xx/B:1_1_1@xx|xx/C:2+1+1@JPN&0/D:xx!xx#xx$xx%xx|xx&xx;xx-xx/E:xx]xx^2=2/4~100!1@120#48+xx]1$1|0[12&0]48=0^100~xx#xx_xx;xx$xx&xx%xx[xx|0]0-n^xx+xx~xx=xx@xx$xx!xx%xx#xx|xx|xx-xx&xx&xx+xx[xx;xx]xx;xx~xx~xx^xx^xx@xx[xx#xx=xx!xx~xx+xx!xx^xx/F:A4#7#2-2/4$100$1+45%18;xx/G:xx_xx/H:xx_xx/I:13_13/J:3~3@6\")\n",
    "\n",
    "phonemes = ['pau','xx'] +[\"ny\",\"ty\",\"py\",\"ky\",\"ry\",\"f\",\"br\",\"sil\",\"cl\",\"a\",\"i\",\"u\",\"e\",\"o\",\"k\",\"g\",\"s\",\"z\",\"sh\",\"j\",\"t\",\"d\",\"ch\",\"q\",\"ts\",\"h\",\"b\",\"p\",\"m\",\"y\",\"r\",\"w\",\"N\",\"n\",\"v\" ]\n",
    "pitches = ['xx']+[pitch + str(i) for i in range(1,8) for pitch in [\"C\", \"Db\", \"D\", \"Eb\", \"E\", \"F\", \"Gb\", \"G\", \"Ab\", \"A\", \"Bb\", \"B\"]] \n",
    "\n",
    " \n",
    "lbl_name = ['t0','t1']+['p' + str(i) for i in range(1, 17)] + \\\n",
    "           ['a' + str(i) for i in range(1, 6)] + \\\n",
    "           ['b' + str(i) for i in range(1, 6)] + \\\n",
    "           ['c' + str(i) for i in range(1, 6)] + \\\n",
    "           ['d' + str(i) for i in range(1, 10)] + \\\n",
    "           ['e' + str(i) for i in range(1, 61)] + \\\n",
    "           ['f' + str(i) for i in range(1, 10)] + \\\n",
    "           ['g' + str(i) for i in range(1, 3)] + \\\n",
    "           ['h' + str(i) for i in range(1, 3)] + \\\n",
    "           ['i' + str(i) for i in range(1, 3)] + \\\n",
    "           ['j' + str(i) for i in range(1, 4)] \n",
    "\n",
    "AVG_DURATION =  5.12061306e+02\n",
    "MAX_F0_SIZE = 10000\n",
    "\n",
    "print(len(li[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_model = load_model(local_path+'best_timing.h5')\n",
    "pitch_model = load_model(local_path+'best_pitch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_songs_label_by_file():\n",
    "    labs = []\n",
    "    for i in range(0, 71):\n",
    "        label_file_name = 'nitech_jp_song070_f001_0' + (('0' + str(i)) if i < 10 else str(i)) + '.lab'\n",
    "        if not os.path.isfile(local_path + 'lab/' + label_file_name):\n",
    "            continue\n",
    "        with open(local_path + 'lab/' + label_file_name, 'r') as lab_file:\n",
    "            lines = lab_file.readlines()\n",
    "            params_list = []\n",
    "            for line in lines:\n",
    "                ps = re.findall(reg, line)\n",
    "                params_list.append(ps[0])\n",
    "            temp = []\n",
    "            for params in params_list:\n",
    "                params_temp = {}\n",
    "                for i in range(0, 120):\n",
    "                    params_temp[lbl_name[i]] = params[i]\n",
    "                temp.append(params_temp)\n",
    "            params_list = temp\n",
    "\n",
    "            labs.append(params_list)\n",
    "    return labs\n",
    "\n",
    "\n",
    "def predict_timing(labs, model):\n",
    "    for i in range(0, len(labs)):\n",
    "        inputs = timing_feature_extract(labs[i])\n",
    "        outputs = model.predict(inputs)\n",
    "        current_note_start_time = 0\n",
    "        current_phoneme_duration_set = []\n",
    "        for j in range(0, len(outputs)):\n",
    "            predict_duration = float(outputs[j][0])\n",
    "            t0 = float(labs[i][j]['t0']) / 10000\n",
    "            t1 = float(labs[i][j]['t1']) / 10000\n",
    "            if ((j != len(outputs) - 1) and (j > 0 and math.fabs(current_note_start_time - t0) > 0.01)) or \\\n",
    "                    ((j == len(outputs) - 1) and not (j > 0 and math.fabs(current_note_start_time - t0) > 0.01)):\n",
    "                total_predict_duration = math.fsum(current_phoneme_duration_set)\n",
    "                actual_duration = t0 - current_note_start_time\n",
    "                # 预测长于实际：缩减\n",
    "                if total_predict_duration > actual_duration:\n",
    "                    if actual_duration == 0:\n",
    "                        current_phoneme_duration_set = [0 for pho in range(0, len(current_phoneme_duration_set))]\n",
    "                    else:\n",
    "                        scale = total_predict_duration / actual_duration\n",
    "                        current_phoneme_duration_set = [pho / scale\n",
    "                                                        for pho in current_phoneme_duration_set]\n",
    "                else:\n",
    "                    if total_predict_duration == 0:\n",
    "                        current_phoneme_duration_set = [actual_duration / len(current_phoneme_duration_set)\n",
    "                                                        for pho in range(0, len(current_phoneme_duration_set))]\n",
    "                    else:\n",
    "                        scale = actual_duration / total_predict_duration\n",
    "                        current_phoneme_duration_set = [pho * scale\n",
    "                                                        for pho in current_phoneme_duration_set]\n",
    "\n",
    "                for i2 in range(0, len(current_phoneme_duration_set)):\n",
    "                    labs[i][j - i2 - 1]['t3'] = current_phoneme_duration_set[i2]\n",
    "\n",
    "                current_note_start_time = t0\n",
    "                # print(\"modified set%s, sum:%s, acutal:%s\"%(current_phoneme_duration_set,math.fsum(current_phoneme_duration_set),actual_duration))\n",
    "\n",
    "                current_phoneme_duration_set = []\n",
    "                \n",
    "            if j == len(outputs) - 1 and (j > 0 and math.fabs(current_note_start_time - t0) > 0.01): \n",
    "                labs[i][j]['t3'] = t1 - t0\n",
    "            # labs[i][j]['t3'] = \n",
    "            current_phoneme_duration_set.append(predict_duration\n",
    "                                                if predict_duration > 0 else 0)\n",
    "\n",
    "            # labs[i][j]['t0'] = outputs[0][0]\n",
    "            # labs[i][j]['t1'] = outputs[0][1]\n",
    "\n",
    "    return labs\n",
    "\n",
    "\n",
    "\n",
    "def read_songs_labels():\n",
    "    labs = None\n",
    "    for i in range(0, 71):\n",
    "        label_file_name = 'nitech_jp_song070_f001_0' + (('0' + str(i)) if i < 10 else str(i)) + '.lab'\n",
    "        if not os.path.isfile(local_path + 'lab/' + label_file_name):\n",
    "            continue\n",
    "        with open(local_path + 'lab/' + label_file_name, 'r') as lab_file:\n",
    "            lines = lab_file.readlines()\n",
    "            params_list = []\n",
    "            for line in lines:\n",
    "                ps = re.findall(reg, line)\n",
    "                params_list.append(ps[0])\n",
    "            temp = []\n",
    "            for params in params_list:\n",
    "                params_temp = {}\n",
    "                for i in range(0, 120):\n",
    "                    params_temp[lbl_name[i]] = params[i]\n",
    "                temp.append(params_temp)\n",
    "            params_list = temp\n",
    "            if labs is None:\n",
    "                labs = np.array(params_list)\n",
    "            else:\n",
    "                labs = np.append(labs, np.array(params_list))\n",
    "    return labs\n",
    "\n",
    "\n",
    "def make_one_hot(data1, size):\n",
    "    data1 = np.array(data1)\n",
    "    return (np.arange(size) == data1[:, None]).astype(np.integer)\n",
    "\n",
    "\n",
    "def make_class(data, classes):\n",
    "    return [classes.index(p) for p in data]\n",
    "\n",
    "def get_params_by_name(name, params_list):\n",
    "    return [params[name] for params in params_list]\n",
    "\n",
    "\n",
    "def convert_params_to_one_hot(name, classes, params_list):\n",
    "    data = get_params_by_name(name, params_list)\n",
    "    data = make_class(data, classes)\n",
    "    data = make_one_hot(data, len(classes))\n",
    "    return data\n",
    "\n",
    "\n",
    "def feature_expend(labs):\n",
    "    modified_labs = []\n",
    "    for index, lab_file in enumerate(labs):\n",
    "        modified_labs.append([])\n",
    "        max_time_stamp = int(lab_file[-1][\"t1\"])\n",
    "        f0_size = math.ceil((max_time_stamp / 10000 / 5)) + 1\n",
    "        sample_index = 0\n",
    "        for sample in range(0, f0_size):\n",
    "            if int(lab_file[sample_index][\"t1\"]) / 10000 / 5 > sample:\n",
    "                modified_labs[index].append(lab_file[sample_index])\n",
    "            else:\n",
    "                if len(lab_file) > sample_index + 1:\n",
    "                    sample_index += 1\n",
    "                modified_labs[index].append(lab_file[sample_index])\n",
    "\n",
    "    return modified_labs\n",
    "\n",
    "\n",
    "def feature_expend_for_duration(labs):\n",
    "    modified_labs = []\n",
    "    for index, lab_file in enumerate(labs):\n",
    "        modified_labs.append([])\n",
    "        max_time_stamp = int(lab_file[-1][\"t1\"])\n",
    "        f0_size = math.ceil((max_time_stamp / 10000 / 5)) + 1\n",
    "        sample_index = 0\n",
    "        for sample in lab_file:\n",
    "            for i in range(0,int(round(sample['t3']/5))):\n",
    "                modified_labs[index].append(sample)\n",
    "        # print('predict:%s,actual:%s'%(len(modified_labs[index]),f0_size))        \n",
    "    return modified_labs\n",
    "\n",
    "\n",
    "def timing_feature_extract(lab):\n",
    "    t0 = np.array(get_params_by_name('t0', lab)).astype(float) / 10000\n",
    "    t1 = np.array(get_params_by_name('t1', lab)).astype(float) / 10000\n",
    "    params_phoneme_duration = t1 - t0\n",
    "\n",
    "    params_phoneme_duration_pre = np.insert(params_phoneme_duration[:-1], 0, AVG_DURATION)\n",
    "    params_phoneme_duration_next = np.append(params_phoneme_duration[1:], AVG_DURATION)\n",
    "    params_phonemes_one_hot = convert_params_to_one_hot('p4', phonemes, lab)\n",
    "    params_phonemes_pre_one_hot = convert_params_to_one_hot('p3', phonemes, lab)\n",
    "    params_phonemes_next_one_hot = convert_params_to_one_hot('p5', phonemes, lab)\n",
    "    params_pitches_one_hot = convert_params_to_one_hot('e1', pitches, lab)\n",
    "    params_pitches_pre_one_hot = convert_params_to_one_hot('d1', pitches, lab)\n",
    "    params_pitches_next_one_hot = convert_params_to_one_hot('f1', pitches, lab)\n",
    "\n",
    "    stacked_feature = np.hstack([params_phonemes_one_hot,\n",
    "                                 params_phonemes_pre_one_hot,\n",
    "                                 params_phonemes_next_one_hot,\n",
    "                                 params_pitches_one_hot,\n",
    "                                 params_pitches_pre_one_hot,\n",
    "                                 params_pitches_next_one_hot,\n",
    "                                 np.reshape(t0, (len(t0), 1)),\n",
    "                                 np.reshape(t1, (len(t1), 1)),\n",
    "                                 np.reshape(params_phoneme_duration, (len(params_phoneme_duration), 1)),\n",
    "                                 np.reshape(params_phoneme_duration_pre, (len(params_phoneme_duration_pre), 1)),\n",
    "                                 np.reshape(params_phoneme_duration_next, (len(params_phoneme_duration_next), 1)),\n",
    "                                 ])\n",
    "    return stacked_feature\n",
    "\n",
    "\n",
    "def pitch_feature_extract(labs):\n",
    "    stacked_labs_with_feature = []\n",
    "    feature_num = 0\n",
    "\n",
    "    temp = []\n",
    "    for lab in labs:\n",
    "        temp.append(len(lab))\n",
    "    max_sample_size = max(temp)\n",
    "    print(\"max sample size: %s\" % max_sample_size)\n",
    "\n",
    "    for lab in labs:\n",
    "        # t0 = np.array(get_params_by_name('t0', lab)).astype(float) / 10000\n",
    "        # t1 = np.array(get_params_by_name('t1', lab)).astype(float) / 10000\n",
    "        t3 = np.array(get_params_by_name('t3', lab)).astype(float)\n",
    "        # params_phoneme_duration = t1 - t0\n",
    "        params_phoneme_duration = t3\n",
    "\n",
    "        params_phoneme_duration_pre = np.insert(params_phoneme_duration[:-1], 0, AVG_DURATION)\n",
    "        params_phoneme_duration_next = np.append(params_phoneme_duration[1:], AVG_DURATION)\n",
    "        params_phonemes_one_hot = convert_params_to_one_hot('p4', phonemes, lab)\n",
    "        params_phonemes_pre_one_hot = convert_params_to_one_hot('p3', phonemes, lab)\n",
    "        params_phonemes_next_one_hot = convert_params_to_one_hot('p5', phonemes, lab)\n",
    "        params_pitches_one_hot = convert_params_to_one_hot('e1', pitches, lab)\n",
    "        params_pitches_pre_one_hot = convert_params_to_one_hot('d1', pitches, lab)\n",
    "        params_pitches_next_one_hot = convert_params_to_one_hot('f1', pitches, lab)\n",
    "\n",
    "        stacked_feature = np.hstack([params_phonemes_one_hot,\n",
    "                                     params_phonemes_pre_one_hot,\n",
    "                                     params_phonemes_next_one_hot,\n",
    "                                     params_pitches_one_hot,\n",
    "                                     params_pitches_pre_one_hot,\n",
    "                                     params_pitches_next_one_hot,\n",
    "                                     np.reshape(params_phoneme_duration, (len(params_phoneme_duration), 1)),\n",
    "                                     np.reshape(params_phoneme_duration_pre, (len(params_phoneme_duration_pre), 1)),\n",
    "                                     np.reshape(params_phoneme_duration_next, (len(params_phoneme_duration_next), 1)),\n",
    "                                     ])\n",
    "        stacked_feature = np.vstack([stacked_feature,\n",
    "                                     np.zeros((max_sample_size - stacked_feature.shape[0], stacked_feature.shape[1]))])\n",
    "\n",
    "        stacked_labs_with_feature.append(stacked_feature)\n",
    "\n",
    "    stacked_labs_with_feature = np.array(stacked_labs_with_feature)\n",
    "    return stacked_labs_with_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sample size: 577\n"
     ]
    }
   ],
   "source": [
    "labs0 = read_songs_label_by_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sample size: 577\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labs1= predict_timing(copy.copy(labs0),timing_model)\n",
    "labs2 = feature_expend(copy.copy(labs1))\n",
    "stacked_labs_with_feature = pitch_feature_extract(copy.copy(labs2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 29757, 369)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labs_with_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29761\n max_f0_size:29761\n"
     ]
    }
   ],
   "source": [
    "def read_f0s():\n",
    "    max_f0_size = 0\n",
    "    f0s = []\n",
    "    for i in range(0, 71):\n",
    "        f0_file_name = 'nitech_jp_song070_f001_0' + (('0' + str(i)) if i < 10 else str(i)) + '_f0.txt'\n",
    "        if not os.path.isfile(local_path+'gen/' + f0_file_name):\n",
    "            continue\n",
    "        with open(local_path+'gen/' + f0_file_name, 'r') as f0_file:\n",
    "            lines = f0_file.readlines()\n",
    "            lines = np.array(lines).astype(np.float)\n",
    "\n",
    "            if len(lines) > max_f0_size:\n",
    "                max_f0_size = len(lines)\n",
    "            f0s.append(lines)\n",
    "    \n",
    "    # 即要生成的最多个f0，\n",
    "    print(max_f0_size)\n",
    "\n",
    "    for index, f0 in enumerate(f0s):\n",
    "        f0s[index] = np.append(f0, np.zeros(max_f0_size - len(f0)))\n",
    "\n",
    "    f0s = np.array(f0s)\n",
    "    f0s = np.reshape(f0s, (f0s.shape[0], f0s.shape[1], 1))\n",
    "    return f0s, max_f0_size\n",
    "\n",
    "\n",
    "\n",
    "f0s, max_f0_size = read_f0s()\n",
    "print(\" max_f0_size:%s\"%( max_f0_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(f0s.shape)\n",
    "# print(stacked_labs_with_feature.shape)\n",
    "# max_f0_size\n",
    "def wavenetBlock(n_atrous_filters, atrous_filter_size, dilation_rate):\n",
    "    def f(input_):\n",
    "        residual = input_\n",
    "        tanh_out = Conv1D(n_atrous_filters, atrous_filter_size,\n",
    "                          dilation_rate=dilation_rate,\n",
    "                          padding='causal',\n",
    "\n",
    "                          activation='tanh')(input_)\n",
    "        sigmoid_out = Conv1D(n_atrous_filters, atrous_filter_size,\n",
    "                             dilation_rate=dilation_rate,\n",
    "                             padding='causal',\n",
    "                             activation='sigmoid')(input_)\n",
    "        merged = Multiply()([tanh_out, sigmoid_out])\n",
    "        skip_out = Conv1D(1, 1, activation='relu', padding='same')(merged)\n",
    "        out = Add()([skip_out, residual])\n",
    "        return out, skip_out\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_basic_generative_model(input_dim):\n",
    "    input_ = Input(shape=(input_dim, 1))\n",
    "    A, B = wavenetBlock(64, 2, 2)(input_)\n",
    "    skip_connections = [B]\n",
    "    for i in range(20):\n",
    "        A, B = wavenetBlock(64, 2, 2 ** ((i + 2) % 9))(A)\n",
    "        skip_connections.append(B)\n",
    "    net = Add()(skip_connections)\n",
    "    net = Activation('relu')(net)\n",
    "    net = Convolution1D(1, 1, activation='relu')(net)\n",
    "    net = Convolution1D(1, 1)(net)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1000, activation='softmax')(net)\n",
    "    model = Model(input=input_, output=net)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def frame_generator(total_frame, input_data_size, frame_shift, control_input, minibatch_size=20):\n",
    "    X = []\n",
    "    y = []\n",
    "    while 1:\n",
    "\n",
    "        for lab_file_index in range(0, len(total_frame)):\n",
    "            total_frame_len = len(total_frame[lab_file_index])\n",
    "\n",
    "            # for cold_start_index in range(0,input_data_size):\n",
    "            #     frame=np.zeros((input_data_size-cold_start_index,1))\n",
    "            #     frame = np.append(frame,total_frame[lab_file_index][:cold_start_index])\n",
    "            #     frame = np.append(frame,control_input[lab_file_index][cold_start_index])\n",
    "            #     X.append(frame.reshape((input_data_size+control_input.shape[2],1)))\n",
    "            # \n",
    "            #     temp = total_frame[lab_file_index][cold_start_index]\n",
    "            #     target_val = int(temp)\n",
    "            #     y.append((np.eye(1000)[target_val]))\n",
    "\n",
    "            for i in range(0, total_frame_len - input_data_size - 1, frame_shift):\n",
    "\n",
    "                # 获取一帧\n",
    "                frame = total_frame[lab_file_index][i:i + input_data_size]\n",
    "\n",
    "                if len(frame) < input_data_size:\n",
    "                    break\n",
    "\n",
    "                if i + input_data_size >= total_frame_len:\n",
    "                    break\n",
    "\n",
    "                # 获取该帧 frame 后面的那个sample\n",
    "                temp = total_frame[lab_file_index][i + input_data_size]\n",
    "                target_val = int(temp)\n",
    "\n",
    "                # frame.shape = (64,1)\n",
    "\n",
    "                # Control Input\n",
    "                frame = np.append(frame, control_input[lab_file_index][i + input_data_size])\n",
    "                # print(frame.shape)\n",
    "\n",
    "                # X值即前一帧\n",
    "                X.append(frame.reshape((input_data_size + control_input.shape[2], 1)))\n",
    "\n",
    "                # 相当于一个one hot vec. 只激活第target_val个元素\n",
    "                y.append((np.eye(1000)[target_val]))\n",
    "\n",
    "                # 获取一个mini-batch的数据返回\n",
    "                if len(X) == minibatch_size:\n",
    "                    yield np.array(X), np.array(y)\n",
    "                    X = []\n",
    "                    y = []\n",
    "\n",
    "\n",
    "def f0_generate(model, f0_window_size,input_size, control_input):\n",
    "    print('Generating audio...')\n",
    "    new_f0s = np.zeros(MAX_F0_SIZE)\n",
    "    seed_audio = np.zeros(f0_window_size)\n",
    "    curr_sample_idx = 0\n",
    "    while curr_sample_idx < new_f0s.shape[0]:\n",
    "        seed = np.append(seed_audio, control_input[curr_sample_idx])\n",
    "\n",
    "        distribution = np.array(model.predict(seed.reshape(1, input_size, 1)\n",
    "                                              ), dtype=float).reshape(1000)\n",
    "\n",
    "        # 让output变成一个零和的输出\n",
    "        distribution /= distribution.sum().astype(float)\n",
    "\n",
    "        # 按照几率输出预测值（很厉害），即把one hot转换成了单一数值\n",
    "        predicted_val = np.random.choice(range(1000), p=distribution)\n",
    "        \n",
    "        new_f0s[curr_sample_idx] = predicted_val\n",
    "        seed_audio[:-1] = seed_audio[1:]\n",
    "        seed_audio[-1] = predicted_val\n",
    "\n",
    "        # percent\n",
    "        # pc_str = str(round(100 * curr_sample_idx / float(new_audio.shape[0]), 2))\n",
    "        # sys.stdout.write('Percent complete: ' + pc_str + '\\r')\n",
    "        # sys.stdout.flush()\n",
    "        curr_sample_idx += 1\n",
    "        if curr_sample_idx % int(new_f0s.shape[0]/10) ==0:\n",
    "            print(curr_sample_idx / int(new_f0s.shape[0]/10))\n",
    "    print('Audio generated.')\n",
    "    return new_f0s.astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\nAudio generated.\n"
     ]
    }
   ],
   "source": [
    "input_data_size = 64\n",
    "f0s_new = f0_generate(pitch_model, input_data_size, input_data_size +\n",
    "                      stacked_labs_with_feature.shape[2],\n",
    "                      stacked_labs_with_feature[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 577, 369)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labs_with_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_model = load_model(local_path+'best_pitch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(local_path+\"new_f0s_with_timing.txt\",'w',encoding='utf-8') as f:\n",
    "    for i in range(0,len(f0s_new)):\n",
    "        f.write(str(f0s_new[i])+\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.20000000e+03,\n       1.20000000e+03, 3.48675497e+02, 4.50000000e+02])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = timing_feature_extract(labs1[0])\n",
    "# outputs = timing_model.predict(inputs)\n",
    "# print(outputs)\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'soundfile'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-fc64b96f8893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'soundfile'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
