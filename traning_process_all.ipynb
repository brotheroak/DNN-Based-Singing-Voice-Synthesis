{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n/Users/Zizy/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "reg = \"(.*) (.*) (.*)\\@(.*)\\^(.*)\\-(.*)\\+(.*)\\=(.*)\\_(.*)\\%(.*)\\^(.*)\\_(.*)\\~(.*)\\-(.*)\\!(.*)\\[(.*)\\$(.*)\\](.*)/A:(.*)\\-(.*)\\-(.*)\\@(.*)\\~(.*)/B:(.*)\\_(.*)\\_(.*)\\@(.*)\\|(.*)/C:(.*)\\+(.*)\\+(.*)\\@(.*)\\&(.*)/D:(.*)\\!(.*)\\#(.*)\\$(.*)\\%(.*)\\|(.*)\\&(.*)\\;(.*)\\-(.*)/E:(.*)\\](.*)\\^(.*)\\=(.*)\\~(.*)\\!(.*)\\@(.*)\\#(.*)\\+(.*)\\](.*)\\$(.*)\\|(.*)\\[(.*)\\&(.*)\\](.*)\\=(.*)\\^(.*)\\~(.*)\\#(.*)\\_(.*)\\;(.*)\\$(.*)\\&(.*)\\%(.*)\\[(.*)\\|(.*)\\](.*)\\-(.*)\\^(.*)\\+(.*)\\~(.*)\\=(.*)\\@(.*)\\$(.*)\\!(.*)\\%(.*)\\#(.*)\\|(.*)\\|(.*)\\-(.*)\\&(.*)\\&(.*)\\+(.*)\\[(.*)\\;(.*)\\](.*)\\;(.*)\\~(.*)\\~(.*)\\^(.*)\\^(.*)\\@(.*)\\[(.*)\\#(.*)\\=(.*)\\!(.*)\\~(.*)\\+(.*)\\!(.*)\\^(.*)/F:(.*)\\#(.*)\\#(.*)\\-(.*)\\$(.*)\\$(.*)\\+(.*)\\%(.*)\\;(.*)/G:(.*)\\_(.*)/H:(.*)\\_(.*)/I:(.*)\\_(.*)/J:(.*)\\~(.*)\\@(.*)\"\n",
    "li = re.findall(reg,\"0 12000000 p@xx^xx-pau+d=e_xx%xx^00_00~00-1!1[xx$xx]xx/A:xx-xx-xx@xx~xx/B:1_1_1@xx|xx/C:2+1+1@JPN&0/D:xx!xx#xx$xx%xx|xx&xx;xx-xx/E:xx]xx^2=2/4~100!1@120#48+xx]1$1|0[12&0]48=0^100~xx#xx_xx;xx$xx&xx%xx[xx|0]0-n^xx+xx~xx=xx@xx$xx!xx%xx#xx|xx|xx-xx&xx&xx+xx[xx;xx]xx;xx~xx~xx^xx^xx@xx[xx#xx=xx!xx~xx+xx!xx^xx/F:A4#7#2-2/4$100$1+45%18;xx/G:xx_xx/H:xx_xx/I:13_13/J:3~3@6\")\n",
    "\n",
    "phonemes = ['pau','xx'] +[\"ny\",\"ty\",\"py\",\"ky\",\"ry\",\"f\",\"br\",\"sil\",\"cl\",\"a\",\"i\",\"u\",\"e\",\"o\",\"k\",\"g\",\"s\",\"z\",\"sh\",\"j\",\"t\",\"d\",\"ch\",\"q\",\"ts\",\"h\",\"b\",\"p\",\"m\",\"y\",\"r\",\"w\",\"N\",\"n\",\"v\" ]\n",
    "pitches = ['xx']+[pitch + str(i) for i in range(1,8) for pitch in [\"C\", \"Db\", \"D\", \"Eb\", \"E\", \"F\", \"Gb\", \"G\", \"Ab\", \"A\", \"Bb\", \"B\"]] \n",
    "\n",
    "local_path='/Users/Zizy/Programming/HKU/Dissertation/'\n",
    "\n",
    "lbl_name = ['t0','t1']+['p' + str(i) for i in range(1, 17)] + \\\n",
    "           ['a' + str(i) for i in range(1, 6)] + \\\n",
    "           ['b' + str(i) for i in range(1, 6)] + \\\n",
    "           ['c' + str(i) for i in range(1, 6)] + \\\n",
    "           ['d' + str(i) for i in range(1, 10)] + \\\n",
    "           ['e' + str(i) for i in range(1, 61)] + \\\n",
    "           ['f' + str(i) for i in range(1, 10)] + \\\n",
    "           ['g' + str(i) for i in range(1, 3)] + \\\n",
    "           ['h' + str(i) for i in range(1, 3)] + \\\n",
    "           ['i' + str(i) for i in range(1, 3)] + \\\n",
    "           ['j' + str(i) for i in range(1, 4)] \n",
    "\n",
    "\n",
    "print(len(li[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_songs_labels():\n",
    "    labs = []\n",
    "    for i in range(0, 71):\n",
    "        label_file_name = 'nitech_jp_song070_f001_0' + (('0' + str(i)) if i < 10 else str(i)) + '.lab'\n",
    "        if not os.path.isfile(local_path+'lab/' + label_file_name):\n",
    "            continue\n",
    "        with open(local_path+'lab/' + label_file_name, 'r') as lab_file:\n",
    "            lines = lab_file.readlines()\n",
    "            params_list = []\n",
    "            for line in lines:\n",
    "                ps = re.findall(reg, line)\n",
    "                params_list.append(ps[0])\n",
    "            temp = []\n",
    "            for params in params_list:\n",
    "                params_temp = {}\n",
    "                for i in range(0, 120):\n",
    "                    params_temp[lbl_name[i]] = params[i]\n",
    "                temp.append(params_temp)\n",
    "            params_list = temp    \n",
    "\n",
    "            labs.append(params_list)\n",
    "    return labs\n",
    "\n",
    "\n",
    "def make_one_hot(data1, size):\n",
    "    data1 = np.array(data1)\n",
    "    return (np.arange(size) == data1[:, None]).astype(np.integer)\n",
    "\n",
    "\n",
    "def make_class(data, classes):\n",
    "    return [classes.index(p) for p in data]\n",
    "\n",
    "def get_params_by_name(name,params_list):\n",
    "    return [params[name] for params in params_list]\n",
    "\n",
    "\n",
    "def convert_params_to_one_hot(name, classes,params_list):\n",
    "    data = get_params_by_name(name,params_list)\n",
    "    data = make_class(data, classes)\n",
    "    data = make_one_hot(data, len(classes))\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs  = read_songs_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sample size: 577\n"
     ]
    }
   ],
   "source": [
    "stacked_labs_with_feature = []\n",
    "\n",
    "temp = []\n",
    "for lab in labs:\n",
    "    temp.append(len(lab))\n",
    "max_sample_size = max(temp)\n",
    "print(\"max sample size: %s\" % max_sample_size)\n",
    "\n",
    "for lab in labs:\n",
    "    t0 = np.array(get_params_by_name('t0', lab)).astype(float) / 10000\n",
    "    t1 = np.array(get_params_by_name('t1', lab)).astype(float) / 10000\n",
    "    params_phoneme_duration = t1 - t0\n",
    "\n",
    "    params_phoneme_duration_pre = np.insert(params_phoneme_duration[:-1], 0, np.average(params_phoneme_duration))\n",
    "    params_phoneme_duration_next = np.append(params_phoneme_duration[1:], np.average(params_phoneme_duration))\n",
    "    params_phonemes_one_hot = convert_params_to_one_hot('p4', phonemes, lab)\n",
    "    params_phonemes_pre_one_hot = convert_params_to_one_hot('p3', phonemes, lab)\n",
    "    params_phonemes_next_one_hot = convert_params_to_one_hot('p5', phonemes, lab)\n",
    "    params_pitches_one_hot = convert_params_to_one_hot('e1', pitches, lab)\n",
    "    params_pitches_pre_one_hot = convert_params_to_one_hot('d1', pitches, lab)\n",
    "    params_pitches_next_one_hot = convert_params_to_one_hot('f1', pitches, lab)\n",
    "\n",
    "    stacked_feature = np.hstack([params_phonemes_one_hot,\n",
    "                                 params_phonemes_pre_one_hot,\n",
    "                                 params_pitches_one_hot,\n",
    "                                 params_pitches_pre_one_hot,\n",
    "                                 params_pitches_next_one_hot,\n",
    "                                 np.reshape(params_phoneme_duration, (len(params_phoneme_duration), 1)),\n",
    "                                 np.reshape(params_phoneme_duration_pre, (len(params_phoneme_duration_pre), 1)),\n",
    "                                 np.reshape(params_phoneme_duration_next, (len(params_phoneme_duration_next), 1)),\n",
    "                                 ])\n",
    "    stacked_feature = np.vstack([stacked_feature, \n",
    "                                 np.zeros((max_sample_size-stacked_feature.shape[0],stacked_feature.shape[1]))])\n",
    "\n",
    "    stacked_labs_with_feature.append(stacked_feature)\n",
    "\n",
    "stacked_labs_with_feature = np.array(stacked_labs_with_feature)\n",
    "# np.reshape(stacked_labs_with_feature ,(31, max_sample_size, 314))\n",
    "# print(len(stacked_labs_with_feature))\n",
    "# print(stacked_labs_with_feature[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29761\n"
     ]
    }
   ],
   "source": [
    "def read_f0s():\n",
    "    max_f0_size = 0\n",
    "    f0s = []\n",
    "    for i in range(0, 71):\n",
    "        f0_file_name = 'nitech_jp_song070_f001_0' + (('0' + str(i)) if i < 10 else str(i)) + '_f0.txt'\n",
    "        if not os.path.isfile(local_path+'gen/' + f0_file_name):\n",
    "            continue\n",
    "        with open(local_path+'gen/' + f0_file_name, 'r') as f0_file:\n",
    "            lines = f0_file.readlines()\n",
    "            lines = np.array(lines).astype(np.float)\n",
    "\n",
    "            if len(lines) > max_f0_size:\n",
    "                max_f0_size = len(lines)\n",
    "            f0s.append(lines)\n",
    "    print(max_f0_size)\n",
    "\n",
    "    for index, f0 in enumerate(f0s):\n",
    "        f0s[index] = np.append(f0, np.zeros(max_f0_size - len(f0)))\n",
    "\n",
    "    f0s = np.array(f0s)\n",
    "    f0s = np.reshape(f0s, (f0s.shape[0], f0s.shape[1], 1))\n",
    "    return f0s, max_f0_size\n",
    "\n",
    "\n",
    "f0s, max_f0_size = read_f0s()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 29761, 1)\n(31, 577, 332)\n"
     ]
    }
   ],
   "source": [
    "print(f0s.shape)\n",
    "print(stacked_labs_with_feature.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zizy/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n  from ipykernel import kernelapp as app\n/Users/Zizy/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=False, units=500, input_shape=(None, 332...)`\n  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zizy/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"linear\")`\n/Users/Zizy/anaconda/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_5 (LSTM)                (None, 500)               1666000   \n_________________________________________________________________\ndense_5 (Dense)              (None, 500)               250500    \n_________________________________________________________________\nrepeat_vector_3 (RepeatVecto (None, 29761, 500)        0         \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 29761, 500)        2002000   \n_________________________________________________________________\ntime_distributed_3 (TimeDist (None, 29761, 1)          501       \n=================================================================\nTotal params: 3,919,001\nTrainable params: 3,919,001\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\nEpoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-56c8e3794b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_labs_with_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Zizy/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(input_dim=332, output_dim=500, return_sequences=False))\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "model.add(RepeatVector(max_f0_size))\n",
    "model.add(LSTM(500, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(output_dim=1, activation=\"linear\")))\n",
    "model.compile(loss=\"mse\",metrics=['accuracy'], optimizer=optimizers.Adam(lr=0.1,epsilon=1e-08))\n",
    "model.summary()\n",
    "model.fit(stacked_labs_with_feature, f0s, nb_epoch=100, batch_size=1, verbose=1,validation_split=0.1)\n",
    "res = model.predict(stacked_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
